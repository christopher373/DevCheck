{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b153432",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "\n",
    "**Definition:** An optimizer is an algorithm that adjusts the parameters of a model to minimize a given loss function during training. It aims to solve the following general optimization problem:\n",
    "\n",
    "$$\\min_{\\theta\\in\\mathcal{D}}\\mathcal{L}(\\theta)$$\n",
    "\n",
    "Where:\n",
    "\n",
    " - $\\theta \\in \\mathbb{R}^d$ is the parameter vector\n",
    " - $\\mathcal{L}: \\mathcal{D} \\subseteq \\mathbb{R}^d \\to \\mathbb{R}$ is the objective (or loss) function,\n",
    " - $\\mathcal{D}$ is the domain (possibly with constraints),\n",
    " - The goal is to find $\\theta^* \\in \\mathcal{D}$ such that:\n",
    "\n",
    " $$\\mathcal{L}(\\theta^*)=\\inf_{\\theta\\in\\mathcal{D}}\\mathcal{L}(\\theta)$$\n",
    "\n",
    "\n",
    "An optimizer defines an **update rule** that generates a sequence of parameter vectors:\n",
    "\n",
    "$$\n",
    "\\theta^{(0)}, \\theta^{(1)}, \\theta^{(2)}, \\dots\n",
    "$$\n",
    "\n",
    "such that ideally:\n",
    "\n",
    "$$\n",
    "\\lim_{k \\to \\infty} \\mathcal{L}(\\theta^{(k)}) \\to \\inf_{\\theta \\in \\mathcal{D}} \\mathcal{L}(\\theta)\n",
    "$$\n",
    "\n",
    "Each update follows a general form:\n",
    "\n",
    "$$\n",
    "\\theta^{(k+1)} = \\mathcal{A}(\\theta^{(k)}, \\mathcal{L}, \\nabla \\mathcal{L}, k, \\ldots)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f00328",
   "metadata": {},
   "source": [
    "### Optimizer Bias\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c63c10",
   "metadata": {},
   "source": [
    "\n",
    "#### Gradient Estimation Bias\n",
    "\n",
    "If $\\xi^{(k)}$ introduces a stochastic gradient estimate:\n",
    "\n",
    "$$\n",
    "g^{(k)} = \\nabla \\mathcal{L}_{\\xi^{(k)}}(\\theta^{(k)})\n",
    "$$\n",
    "\n",
    "Then bias is defined as:\n",
    "\n",
    "$$\n",
    "\\text{Bias}[g^{(k)}] = \\mathbb{E}_{\\xi^{(k)}}[g^{(k)}] - \\nabla \\mathcal{L}(\\theta^{(k)})\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ecbd5",
   "metadata": {},
   "source": [
    "\n",
    "#### Trajectory Bias\n",
    "\n",
    "Even with unbiased gradients, the update rule may induce a biased trajectory:\n",
    "\n",
    "$$\n",
    "\\theta^{(k+1)} = \\theta^{(k)} + \\Delta \\theta^{(k)}\n",
    "$$\n",
    "\n",
    "with:\n",
    "\n",
    "$$\n",
    "\\Delta \\theta^{(k)} = \\mathcal{F}(\\{\\nabla \\mathcal{L}(\\theta^{(j)})\\}_{j \\le k})\n",
    "$$\n",
    "\n",
    "If the limit $\\theta^* = \\lim_{k \\to \\infty} \\theta^{(k)}$ satisfies:\n",
    "\n",
    "$$\n",
    "\\theta^* \\ne \\arg\\min_\\theta \\mathcal{L}(\\theta)\n",
    "$$\n",
    "\n",
    "then the optimizer is **biased toward a non-optimal solution**, often due to its internal dynamics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c2df85",
   "metadata": {},
   "source": [
    "\n",
    "#### Solution Bias\n",
    "\n",
    "Let $\\Theta^* = \\{\\theta : \\mathcal{L}(\\theta) = \\mathcal{L}_{\\min} \\}$ denote the set of global minima.\n",
    "\n",
    "If the optimizer consistently selects a specific $\\theta^* \\in \\Theta^*$, then it induces a **selection bias**:\n",
    "\n",
    "$$\n",
    "\\theta^* = \\arg\\min_{\\theta \\in \\Theta^*} R(\\theta)\n",
    "$$\n",
    "\n",
    "where $R(\\theta)$ is some implicit regularization (e.g., norm, sharpness), even if not explicitly part of $\\mathcal{L}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccb33d4",
   "metadata": {},
   "source": [
    "### Gradient Descent (GD)\n",
    "\n",
    "**Update Rule:**\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta \\mathcal{L}(\\theta_t)\n",
    "$$\n",
    "\n",
    "- $\\eta > 0$ is the learning rate.\n",
    "- Uses the full dataset to compute the exact gradient.\n",
    "\n",
    "**Implication:** Converges smoothly to a local minimum if $\\mathcal{L}$ is convex and $\\eta$ is well-chosen. Computationally expensive for large datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e63a398",
   "metadata": {},
   "source": [
    "\n",
    "### Stochastic Gradient Descent (SGD)\n",
    "\n",
    "**Update Rule:**\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\nabla_\\theta \\mathcal{L}(\\theta_t; x_i)\n",
    "$$\n",
    "\n",
    "- Uses a single sample (or mini-batch) at each step.\n",
    "\n",
    "**Implication:** Introduces noise but allows faster iterations. Can escape shallow local minima. Requires learning rate decay or scheduling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ef715a",
   "metadata": {},
   "source": [
    "\n",
    "### Momentum\n",
    "\n",
    "**Update Rule:**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v_{t+1} &= \\mu v_t - \\eta \\nabla_\\theta \\mathcal{L}(\\theta_t) \\\\\n",
    "\\theta_{t+1} &= \\theta_t + v_{t+1}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "- $\\mu \\in [0,1)$ is the momentum coefficient.\n",
    "\n",
    "**Implication:** Helps accelerate learning by smoothing out gradient updates; especially useful in ravines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef70686",
   "metadata": {},
   "source": [
    "\n",
    "### Nesterov Accelerated Gradient (NAG)\n",
    "\n",
    "**Update Rule:**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v_{t+1} &= \\mu v_t - \\eta \\nabla_\\theta \\mathcal{L}(\\theta_t + \\mu v_t) \\\\\n",
    "\\theta_{t+1} &= \\theta_t + v_{t+1}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Implication:** Looks ahead by evaluating the gradient at the approximate future position. Generally converges faster than standard momentum.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7223164b",
   "metadata": {},
   "source": [
    "\n",
    "### Adagrad\n",
    "\n",
    "**Update Rule:**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "G_t &= G_{t-1} + \\nabla_\\theta \\mathcal{L}(\\theta_t)^2 \\\\\n",
    "\\theta_{t+1} &= \\theta_t - \\frac{\\eta}{\\sqrt{G_t + \\epsilon}} \\nabla_\\theta \\mathcal{L}(\\theta_t)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "- Accumulates past squared gradients to adapt learning rates.\n",
    "\n",
    "**Implication:** Works well for sparse data but suffers from aggressive learning rate decay.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b34d353",
   "metadata": {},
   "source": [
    "\n",
    "### RMSprop\n",
    "\n",
    "**Update Rule:**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E[g^2]_t &= \\gamma E[g^2]_{t-1} + (1 - \\gamma) (\\nabla_\\theta \\mathcal{L}(\\theta_t))^2 \\\\\n",
    "\\theta_{t+1} &= \\theta_t - \\frac{\\eta}{\\sqrt{E[g^2]_t + \\epsilon}} \\nabla_\\theta \\mathcal{L}(\\theta_t)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "- $\\gamma$ is typically set to 0.9.\n",
    "\n",
    "**Implication:** Mitigates Adagrad's aggressive decay by using exponential moving average of squared gradients.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70a54f9",
   "metadata": {},
   "source": [
    "\n",
    "### Adam (Adaptive Moment Estimation)\n",
    "\n",
    "**Update Rule:**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "m_t &= \\beta_1 m_{t-1} + (1 - \\beta_1) \\nabla_\\theta \\mathcal{L}(\\theta_t) \\\\\n",
    "v_t &= \\beta_2 v_{t-1} + (1 - \\beta_2) (\\nabla_\\theta \\mathcal{L}(\\theta_t))^2 \\\\\n",
    "\\hat{m}_t &= \\frac{m_t}{1 - \\beta_1^t} \\quad , \\quad \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t} \\\\\n",
    "\\theta_{t+1} &= \\theta_t - \\eta \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "- Typical values: $\\beta_1 = 0.9$, $\\beta_2 = 0.999$, $\\epsilon = 10^{-8}$.\n",
    "\n",
    "**Implication:** Combines momentum and adaptive learning rates. Excellent general-purpose optimizer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3228bc7e",
   "metadata": {},
   "source": [
    "\n",
    "### AdaDelta\n",
    "\n",
    "**Update Rule:**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E[g^2]_t &= \\rho E[g^2]_{t-1} + (1 - \\rho) g_t^2 \\\\\n",
    "\\Delta\\theta_t &= - \\frac{\\sqrt{E[\\Delta\\theta^2]_{t-1} + \\epsilon}}{\\sqrt{E[g^2]_t + \\epsilon}} g_t \\\\\n",
    "E[\\Delta\\theta^2]_t &= \\rho E[\\Delta\\theta^2]_{t-1} + (1 - \\rho)(\\Delta\\theta_t)^2 \\\\\n",
    "\\theta_{t+1} &= \\theta_t + \\Delta\\theta_t\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "- $\\rho \\in [0, 1)$ is typically around 0.9.\n",
    "\n",
    "**Implication:** No need to set a learning rate manually. Effective at stabilizing updates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0fc044",
   "metadata": {},
   "source": [
    "\n",
    "### AdamW\n",
    "\n",
    "**Update Rule:**\n",
    "\n",
    "Similar to Adam, but decouples weight decay:\n",
    "\n",
    "$$\n",
    "\\theta_{t+1} = \\theta_t - \\eta \\left( \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon} + \\lambda \\theta_t \\right)\n",
    "$$\n",
    "\n",
    "- $\\lambda$ is the weight decay coefficient.\n",
    "\n",
    "**Implication:** Regularizes weights more explicitly than standard Adam. Now preferred over Adam for training deep networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a0763d",
   "metadata": {},
   "source": [
    "### Neuron\n",
    "\n",
    "**Definition:** The neuron is a function $f:\\mathbb{R}^n\\rightarrow\\mathbb{R}$ defined as \n",
    "\n",
    "$$f(\\mathbf{x})=\\phi(\\mathbf{w}\\cdot\\bar{\\mathbf{x}})$$\n",
    "\n",
    "where\n",
    "\n",
    " - $\\mathbf{x}\\in\\mathbb{R}^n$ is the input vector\n",
    " - $\\bar{\\mathbf{x}}=\\begin{bmatrix}x\\\\1\\end{bmatrix}\\in\\mathbb{R}^{n+1}$ is the input vector with a 1 for the bias term\n",
    " - $\\mathbf{w}\\in\\mathbb{R}^{n+1}$ is the weight vector with a bias term\n",
    " - $\\phi:\\mathbb{R}\\rightarrow\\mathbb{R}$ is the activation function\n",
    "\n",
    "**Non-linear Activation:** The Universal Approximation Theorem states, a feedforward neural network with a single hidden layer containing a finite number of neurons and a non-linear activation function can approximate any continuous function on compact subsets of $\\mathbb{R}^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a440046d",
   "metadata": {},
   "source": [
    "### Single Layer Neural Network\n",
    "\n",
    "**Definition:** A single layer neural network is a vector-valued function $f:\\mathbb{R}^n\\rightarrow\\mathbb{R}^m$ defined by\n",
    "\n",
    "$$f(\\mathbf{x})=\\phi(\\mathbf{W}\\bar{\\mathbf{x}})$$\n",
    "\n",
    "where\n",
    "\n",
    " - $\\mathbf{x}\\in\\mathbb{R}^n$ is the input vector          w\n",
    " - $\\bar{\\mathbf{x}}=\\begin{bmatrix}x\\\\1\\end{bmatrix}\\in\\mathbb{R}^{n+1}$ is the input vector augmented with a 1 for the bias term,\n",
    " - $\\mathbf{W}\\in\\mathbb{R}^{m\\times(n+1)}$ is the weight matrix, where each row corresponds to the weights (including bias) for one neuron,\n",
    " - $\\phi:\\mathbb{R}\\rightarrow\\mathbb{R}$ is a scalar activation function, extended to vectors in $\\mathbb{R}^m$ by elementwise application of the dot product."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2465c99",
   "metadata": {},
   "source": [
    "### Multi Layer Neural Network\n",
    "\n",
    "\n",
    "**Definition:** A multi layer neural network is a vector-valued function $f:\\mathbb{R}^n\\rightarrow\\mathbb{R}^m$ defined as a composition of affine transformations and activation functions over $L$ layers:\n",
    "\n",
    "$$f(\\mathbf{x})=\\phi^{(L)}(\\mathbf{W}^{(L)}\\cdot\\phi^{(L-1)}(\\mathbf{W}^{(L-1)}\\ldots\\phi^{(1)}(\\mathbf{W}^{(1)}\\cdot\\bar{\\mathbf{x}})\\ldots))$$\n",
    "\n",
    "where\n",
    "\n",
    " - $\\mathbf{x}\\in\\mathbb{R}^n$ is the input vector.\n",
    " - $\\bar{\\mathbf{x}}=\\begin{bmatrix}x\\\\1\\end{bmatrix}\\in\\mathbb{R}^{n+1}$ is the input augmented with a bias term.\n",
    " - $L\\in\\mathbb{N}$ is the total number of layers.\n",
    " - $\\phi^{(\\ell)}:\\mathbb{R}^{d_{\\ell}}\\rightarrow\\mathbb{R}^{d_{\\ell}}$ is an activation function applied component wise.\n",
    " - $\\mathbf{W}^{(\\ell)}\\in\\mathbb{R}^{d_{\\ell}\\times(d_{\\ell-1}+1)}$ is the weight matrix of the $\\ell$-th layer, where $d_0=n$ and $d_L=m$.\n",
    "\n",
    "\n",
    "**Layer-wise Representation:** \n",
    "\n",
    "$$h^{(0)}=\\mathbf{x}$$\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\mathbf{z}^{(\\ell)}&=\\mathbf{W}^{(\\ell)}\\cdot\\bar{\\mathbf{h}}^{(\\ell-1)}&\\text{pre-activation}\\\\\n",
    "\\mathbf{h}^{(\\ell)}&=\\phi^{(\\ell)}(\\mathbf{z}^{(\\ell)})&\\text{post-activation}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826dcf30",
   "metadata": {},
   "source": [
    "\n",
    "### Backpropagation\n",
    "\n",
    "**Definition:** A highly efficient algorithm for indirectly computing the gradient of the loss function with respect to all the weights in a neural network by applying the chain rule in a structured, recursive way.\n",
    "\n",
    "**Algorithm:**\n",
    "\n",
    "*forward pass:* Compute $\\mathbf{z}^{(\\ell)},\\mathbf{h}^{(l)}$ for $\\ell=1,\\ldots,L$.\n",
    "\n",
    "*backward pass:*\n",
    "\n",
    " 1. Initialize $\\delta^{(L)}=\\nabla_{\\mathbf{h}^{(L)}}\\mathcal{L}\\circ\\phi'^{(L)}$\n",
    " 2. For $\\ell=L-1,\\ldots,1$\n",
    "    - $\\boldsymbol{\\delta}^{[\\ell]} = \\left( (\\mathbf{W}^{[\\ell+1]})^\\top \\boldsymbol{\\delta}^{[\\ell+1]} \\right) \\circ \\phi'^{[\\ell]}$\n",
    "\n",
    "**Derivation:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b8352c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
